ğŸ“„ Open Document Intelligence System (GenAI + RAG)

An end-to-end Retrieval-Augmented Generation (RAG) based Open Document Intelligence system that allows users to ask natural-language questions over documents and receive grounded answers using local and open-source GenAI components.

ğŸš€ Key Features

ğŸ“‚ PDF Document Ingestion

âœ‚ï¸ Text Chunking with Overlap

ğŸ§  Semantic Embeddings using HuggingFace

ğŸ” Vector Similarity Search with FAISS

ğŸ¤– Local LLM Integration using Ollama

ğŸ”— LangChain-based RAG Orchestration

ğŸ’¬ Interactive CLI for user queries

ğŸ›¡ï¸ Hallucination-safe responses (context-grounded)

ğŸ§  Why RAG?

Large Language Models can hallucinate when answering questions beyond their training data.
This system uses Retrieval-Augmented Generation (RAG) to:

Retrieve relevant document chunks

Provide them as context to the LLM

Generate answers only from the retrieved content

This ensures accuracy, transparency, and reliability.

ğŸ—ï¸ Architecture Overview
PDF Documents
     â†“
Document Loader
     â†“
Text Chunking
     â†“
HuggingFace Embeddings
     â†“
FAISS Vector Store
     â†“
Retriever
     â†“
Local LLM (Ollama)
     â†“
Final Answer

ğŸ› ï¸ Tech Stack
Component	Technology
Programming Language	Python
LLM Orchestration	LangChain
Embeddings	HuggingFace (Sentence Transformers)
Vector Database	FAISS
LLM	Ollama (local model)
Interface	Command-Line (CLI)
Version Control	Git & GitHub
ğŸ“‚ Project Structure
Open-Intelligence-doc/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ loaders.py        # PDF loading
â”‚   â”œâ”€â”€ chunking.py       # Text splitting logic
â”‚   â”œâ”€â”€ embeddings.py    # Embedding generation
â”‚   â”œâ”€â”€ retriever.py     # FAISS retriever
â”‚   â”œâ”€â”€ rag_chain.py     # RAG pipeline
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents/        # Sample PDFs
â”‚
â”œâ”€â”€ main.py               # Entry point (CLI)
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Manisha1808/Open-Intelligence-doc.git
cd Open-Intelligence-doc

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
.\.venv\Scripts\activate   # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


(or via pyproject.toml if using uv/poetry)

4ï¸âƒ£ Install Ollama & Pull Model

Install Ollama from:
ğŸ‘‰ https://ollama.com

Then pull a model:

ollama pull gemma:2b

â–¶ï¸ Running the Application
python main.py


You will see:

Ask a question:


Example questions:

What topics do the cited papers focus on?

Summarize the document content

What research areas are discussed?

Type exit to quit.

ğŸ›¡ï¸ Hallucination Control

If the answer is not present in the document, the system responds:

"The context does not provide sufficient information to answer this question."

This ensures safe and trustworthy outputs.

ğŸ“Œ Design Decisions

Local LLM (Ollama)
Avoids API cost, quota limits, and privacy concerns.

FAISS for Vector Search
Fast and efficient similarity search for embeddings.

HuggingFace Embeddings
Open-source, reliable semantic representations.

LangChain
Clean abstraction for chaining retrieval and generation.

ğŸ”® Future Enhancements

ğŸ“„ Document-level summaries

ğŸŒ FastAPI backend

ğŸ“¤ File upload support

ğŸ“Š Answer source citations

ğŸ—‚ï¸ Multi-document indexing

ğŸ” Incremental ingestion

ğŸ§  Re-ranking for better retrieval

ğŸ¯ Use Cases

Research paper analysis

Internal document Q&A

Knowledge base assistant

Educational content exploration

Private document intelligence systems

ğŸ‘©â€ğŸ’» Author

Manisha Sen
Computer Science Engineer | Data & GenAI Enthusiast

